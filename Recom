

###########################################################################
#
# Content Based Recommendation: News Aggregator
#
#
# Script:
# Generting relevant articles recommendation for for reader based on 
# current article being read.
#
# Abhinay chaudhary
###########################################################################


library(tidyverse)
library(tidytext)
library(tm)
library(slam)
library(sentimentr)

# Taking a fraction of the data provided and beautifying it...
cnames <- c('ID' , 'TITLE' , 'URL' , 
            'PUBLISHER' , 'CATEGORY' , 
            'STORY' , 'HOSTNAME' ,'TIMESTAMP')

data_full <- read_tsv('newsCorpora.csv', 
                      col_names = cnames,
                      col_types = cols(
                        ID = col_integer(),
                        TITLE = col_character(),
                        URL = col_character(),
                        PUBLISHER = col_character(),
                        CATEGORY = col_character(),
                        STORY = col_character(),
                        HOSTNAME = col_character(),
                        TIMESTAMP = col_double()
                      )
)

data <- dplyr::sample_frac(data_full, 0.1, replace = TRUE)
head(data)

# The following are some distinct publishers and categories:
data %>% group_by(PUBLISHER) %>% summarise()
data %>% group_by(CATEGORY) %>% summarise()

# Let's look a little closer at our publishers:
publisher.count <- data.frame(data %>% group_by(PUBLISHER) %>% summarise(ct =n()))
head(publisher.count)
dim(publisher.count)

# publisher count with less then 10 articles
dim(publisher.count[publisher.count$ct <= 10,])

# Looking at the top 100 publishers
publisher.top <- head(publisher.count[order(-publisher.count$ct),],100)
head(publisher.top)

# For our top 100 publishers, let's now get their articles and other information:
data.subset <- inner_join(publisher.top, data, by = "PUBLISHER")
head(data.subset)
dim(data.subset)

## Similarity index

# we separate our data into two data frames
title.df <- data.subset[,c('ID','TITLE')]
others.df <- data.subset[,c('ID','PUBLISHER','CATEGORY')]

# calling transformations on the corpus
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeWords, stopwords("english"))

inspect(dtm[1:5,10:15])

# cosine distance
sim.score <- tcrossprod_simple_triplet_matrix(dtm)/(sqrt( row_sums(dtm^2) %*% t(row_sums(dtm^2)) ))

## Search

# Let's say we want to find similar articles to article 16947 (the articles in dataset will be different for different executions):
match.docs <- sim.score["16947",]
match.docs

# make a data frame:
match.df <- data.frame(ID = names(match.docs), cosine = match.docs, stringsAsFactors=FALSE)
match.df$ID <- as.integer(match.df$ID)
head(match.df)

# recommend only the top 30 matches:
match.refined<-head(match.df[order(-match.df$cosine),],30)
head(match.refined)

# merge title.df and other.df with match.refined:
match.refined <- inner_join(match.refined, title.df,by = "ID")
match.refined <- inner_join(match.refined, others.df,by = "ID")

head(match.refined)

## Polarity scores

# sentiment function :
sentiment.score <- sentiment(match.refined$TITLE)
head(sentiment.score)

# Calculate the average value of the sentiment scores for each article:
sentiment.score <- sentiment.score %>% group_by(element_id) %>% summarise(sentiment = mean(sentiment))
head(sentiment.score)

# update the match.refined data frame with the polarity scores:
match.refined$polarity <- sentiment.score$sentiment
head(match.refined)

# including prublisher and category columns
target.publisher <- match.refined[1,]$PUBLISHER
target.category <- match.refined[1,]$CATEGORY
target.polarity <- match.refined[1,]$polarity

target.title <- match.refined[1,]$TITLE

# match the publisher and category of document searched for:
match.refined$is.publisher <- match.refined$PUBLISHER == target.publisher
match.refined$is.publisher <- as.numeric(match.refined$is.publisher)

# Now for the category:
match.refined$is.category <- match.refined$CATEGORY == target.category
match.refined$is.category <- as.numeric(match.refined$is.category)

# Jaccard's distance
match.refined$jaccard <- (match.refined$is.publisher + match.refined$is.category)/2

# Manhattan distance
match.refined$polaritydiff <- abs(target.polarity - match.refined$polarity)

range01 <- function(x){(x-min(x))/(max(x)-min(x))}
match.refined$polaritydiff <- range01(unlist(match.refined$polaritydiff))

head(match.refined)

## clean up
match.refined$is.publisher = NULL
match.refined$is.category = NULL
match.refined$polarity = NULL
match.refined$sentiment = NULL

head(match.refined)

## Fuzzy logic Ranking

# Fuzzy limits
library(sets, quietly = TRUE)
sets_options("universe", seq(from = 0,
                             to = 1, by = 0.1))


variables <-
  set(cosine =
        fuzzy_partition(varnames =
                          c(vlow = 0.2, low = 0.4,
                            medium = 0.6, high = 0.8),
                        FUN = fuzzy_cone , radius = 0.2),
      jaccard =
        fuzzy_partition(varnames =
                          c(close = 1.0, halfway = 0.5,
                            far = 0.0),
                        FUN = fuzzy_cone , radius = 0.4),
      
      polarity =
        fuzzy_partition(varnames =
                          c(same = 0.0, similar = 0.3,close = 0.5,
                            away = 0.7),
                        FUN = fuzzy_cone , radius = 0.2),
      ranking =
        fuzzy_partition(varnames =
                          c(H = 1.0, MED = 0.7 , M = 0.5, L = 0.3),
                        FUN = fuzzy_cone , radius = 0.2
        )
  )

# Fuzzy rules
rules <-
  set(
    
    ######### Low Ranking Rules ###################
    fuzzy_rule(cosine %is% vlow, 
               ranking %is% L),
    
    fuzzy_rule(cosine %is% low || jaccard %is% far
               || polarity %is% away,
               ranking %is% L),
    
    fuzzy_rule(cosine %is% low || jaccard %is% halfway
               || polarity %is% away,
               ranking %is% L),
    
    fuzzy_rule(cosine %is% low || jaccard %is% halfway
               || polarity %is% close,
               ranking %is% L),
    
    fuzzy_rule(cosine %is% low || jaccard %is% halfway
               || polarity %is% similar,
               ranking %is% L),
    
    fuzzy_rule(cosine %is% low || jaccard %is% halfway
               || polarity %is% same,
               ranking %is% L),
    
    fuzzy_rule(cosine %is% medium || jaccard %is% far
               || polarity %is% away,
               ranking %is% L),
    
    ############### Medium Ranking Rules ##################
    
    
    fuzzy_rule(cosine %is% low || jaccard %is% close
               || polarity %is% same,
               ranking %is% M),
    
    fuzzy_rule(cosine %is% low && jaccard %is% close
               && polarity %is% similar,
               ranking %is% M),
    
    ############### Median Ranking Rule ##################
    
    
    fuzzy_rule(cosine %is% medium && jaccard %is% close
               && polarity %is% same,
               ranking %is% MED),
    
    fuzzy_rule(cosine %is% medium && jaccard %is% halfway
               && polarity %is% same,
               ranking %is% MED),
    
    fuzzy_rule(cosine %is% medium && jaccard %is% close
               && polarity %is% similar,
               ranking %is% MED),
    
    
    fuzzy_rule(cosine %is% medium && jaccard %is% halfway
               && polarity %is% similar,
               ranking %is% MED),
    
    
    ############## High Ranking Rule #####################
    
    fuzzy_rule(cosine %is% high,ranking %is% H)
    
    
    
  )

ranking.system <- fuzzy_system(variables, rules)
print(ranking.system)

plot(ranking.system)

# The get.ranks function is applied in each row of match.refined to get the fuzzy ranking. Finally, we sort the results using this ranking.
get.ranks <- function(dataframe){
  cosine =  as.numeric(dataframe['cosine'])
  jaccard = as.numeric(dataframe['jaccard'])
  polarity = as.numeric(dataframe['polaritydiff'])
  fi <- fuzzy_inference(ranking.system, list(cosine = cosine,  jaccard = jaccard, polarity=polarity))
  return(gset_defuzzify(fi, "centroid"))
  
}

match.refined$ranking <- apply(match.refined, 1, get.ranks)
match.refined <- match.refined[order(-match.refined$ranking),]
match.refined
view rawcfRecommendation.R 
